{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Vv-17QH2M1fW",
   "metadata": {
    "id": "Vv-17QH2M1fW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We first install and import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "EwUN5g20CFnH",
   "metadata": {
    "id": "EwUN5g20CFnH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ga/anaconda3/lib/python3.8/site-packages (1.13.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ga/anaconda3/lib/python3.8/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ga/anaconda3/lib/python3.8/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ga/anaconda3/lib/python3.8/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ga/anaconda3/lib/python3.8/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/ga/anaconda3/lib/python3.8/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: wheel in /home/ga/anaconda3/lib/python3.8/site-packages (from nvidia-cuda-runtime-cu11==11.7.99->torch) (0.35.1)\n",
      "Requirement already satisfied: setuptools in /home/ga/anaconda3/lib/python3.8/site-packages (from nvidia-cuda-runtime-cu11==11.7.99->torch) (65.5.0)\n",
      "Requirement already satisfied: gym==0.21 in /home/ga/anaconda3/lib/python3.8/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/ga/anaconda3/lib/python3.8/site-packages (from gym==0.21) (1.21.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/ga/anaconda3/lib/python3.8/site-packages (from gym==0.21) (1.6.0)\n",
      "Requirement already satisfied: stable-baselines3==1.6.2 in /home/ga/anaconda3/lib/python3.8/site-packages (1.6.2)\n",
      "Requirement already satisfied: cloudpickle in /home/ga/anaconda3/lib/python3.8/site-packages (from stable-baselines3==1.6.2) (1.6.0)\n",
      "Requirement already satisfied: pandas in /home/ga/anaconda3/lib/python3.8/site-packages (from stable-baselines3==1.6.2) (1.1.3)\n",
      "Requirement already satisfied: matplotlib in /home/ga/anaconda3/lib/python3.8/site-packages (from stable-baselines3==1.6.2) (3.3.2)\n",
      "Requirement already satisfied: gym==0.21 in /home/ga/anaconda3/lib/python3.8/site-packages (from stable-baselines3==1.6.2) (0.21.0)\n",
      "Requirement already satisfied: importlib-metadata~=4.13 in /home/ga/anaconda3/lib/python3.8/site-packages (from stable-baselines3==1.6.2) (4.13.0)\n",
      "Requirement already satisfied: numpy in /home/ga/anaconda3/lib/python3.8/site-packages (from stable-baselines3==1.6.2) (1.21.3)\n",
      "Requirement already satisfied: torch>=1.11 in /home/ga/anaconda3/lib/python3.8/site-packages (from stable-baselines3==1.6.2) (1.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ga/anaconda3/lib/python3.8/site-packages (from pandas->stable-baselines3==1.6.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ga/anaconda3/lib/python3.8/site-packages (from pandas->stable-baselines3==1.6.2) (2020.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ga/anaconda3/lib/python3.8/site-packages (from matplotlib->stable-baselines3==1.6.2) (1.3.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ga/anaconda3/lib/python3.8/site-packages (from matplotlib->stable-baselines3==1.6.2) (8.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ga/anaconda3/lib/python3.8/site-packages (from matplotlib->stable-baselines3==1.6.2) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/ga/anaconda3/lib/python3.8/site-packages (from matplotlib->stable-baselines3==1.6.2) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/ga/anaconda3/lib/python3.8/site-packages (from matplotlib->stable-baselines3==1.6.2) (2020.6.20)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ga/anaconda3/lib/python3.8/site-packages (from importlib-metadata~=4.13->stable-baselines3==1.6.2) (3.4.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ga/anaconda3/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3==1.6.2) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in /home/ga/anaconda3/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3==1.6.2) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ga/anaconda3/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3==1.6.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ga/anaconda3/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3==1.6.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ga/anaconda3/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3==1.6.2) (8.5.0.96)\n",
      "Requirement already satisfied: six>=1.5 in /home/ga/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->stable-baselines3==1.6.2) (1.15.0)\n",
      "Requirement already satisfied: wheel in /home/ga/anaconda3/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable-baselines3==1.6.2) (0.35.1)\n",
      "Requirement already satisfied: setuptools in /home/ga/anaconda3/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable-baselines3==1.6.2) (65.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install gym==0.21\n",
    "!pip install stable-baselines3==1.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a8da3eba",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "from collections import deque\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf7996a",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Acrobot\n",
    "\n",
    "Next, we instantiate the [Acrobot environment](https://www.gymlibrary.dev/environments/classic_control/acrobot/) from OpenAI Gym and gain a quick understanding of its key variables and methods. \n",
    "\n",
    "The Acrobot environment includes a simple robot with two blue links that are connected by two green joints. The joint connecting the two links is actuated, i.e., it can be controlled by the robot by applying torque to the joint. The goal is to swing the free end of the outer link to reach the target height (shown as the black horizontal line) by using robot's actuation.\n",
    "\n",
    "Follow the hyperlinks to learn more about the envionment [Acrobot environment](https://www.gymlibrary.dev/environments/classic_control/acrobot/)  and its [source code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/acrobot.py).\n",
    "\n",
    "![](https://www.gymlibrary.dev/_images/acrobot.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8d0921fc",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"Acrobot-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a32782",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### States\n",
    "\n",
    "OpenAI Gym environments do not explicitly provide state but instead provide observation. In the Acrobot environment, the state and observation are identical. The state of the Acrobot is a 6-dimensional vector, which provides information about the two rotational joint angles of the robot and their angular velocities. As joint angles and velocity are continuous variables, so is the Acrobot state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "82bd1243",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of state features: 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of state features: {env.observation_space.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2aaacf",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Actions\n",
    "\n",
    "In contrast to the continuous state, the action space for this robot is discrete. The robot has only three choices:\n",
    "- apply torque of unit 1 in clockwise direction,\n",
    "- apply torque of until 1 in counter-clockwise direction, or\n",
    "- apply no torque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f9056f59",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of actions: {env.action_space.n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f394c327",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Transition and Reward Function\n",
    "\n",
    "The transition and rewards functions for the environment are not explicitly represented as matrices or tensors. Instead the gym API provides access to the `step` method, which takes in as input an `action` and provides (among other things) an `observation` and `reward`. Also notice the `reset` method, which resets the MDP environment.\n",
    "\n",
    "The following snippet describes the use of `step` and `reset` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8571f351",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: [ 0.99578995  0.09166451  0.9981477   0.06083632  0.06088297 -0.01201279]\n",
      "Action: 0\n",
      "Next state: [ 0.99431396  0.10648803  0.99963915  0.02686246  0.08397561 -0.31978488]\n",
      "Reward: -1.0\n"
     ]
    }
   ],
   "source": [
    "# Reset the environment\n",
    "state = env.reset() \n",
    "print(f\"State: {state}\")\n",
    "\n",
    "# Select a random action to play\n",
    "action = env.action_space.sample()\n",
    "print(f\"Action: {action}\")\n",
    "\n",
    "# Send this action to the environment to receive the next state and reward\n",
    "next_state, reward, done, _ = env.step(action)\n",
    "print(f\"Next state: {next_state}\")\n",
    "print(f\"Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7effcb2d",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Problem 1.1\n",
    "\n",
    "Next, we will implement the general recipe of Q Learning algorithm to compute the optimal policy in the Acrobot environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8994db33",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Q Network\n",
    "\n",
    "Since, the robot's state space is continuous, we cannot represent the Q value function exactly. Instead, we will approximate the Q value as a neural network. Let us first define this neural network. \n",
    "\n",
    "Many choices exist for the neural network architecture. We will utilize a multi-layer perceptron, with\n",
    "- input as the state of the Acrobot, and\n",
    "- output as a vector of size 3 denoting Q values of each action for the input state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "22b07eff",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    \"\"\"Approximates the Q Function as a Multi-Layer Perceptron.\"\"\"\n",
    "\n",
    "    def __init__(self, env, nodes_per_mlp_layer=[128, 64]):\n",
    "        \"\"\"Initialize the Q Function apprixmated as a Multi-Layer Perceptron.\n",
    "        \n",
    "        Args:\n",
    "            env: An OpenAI Gym environment.\n",
    "            nodes_per_mlp_layer: An array of integers. The length of array equals the number\n",
    "                of hidden layers of the Multi-Layer Perceptron. Each element in the array\n",
    "                equals the number of nodes in the corresponding layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        ######## PUT YOUR CODE HERE ########\n",
    "        # input layer\n",
    "        self.input_layer = nn.Linear(env.observation_space.shape[0], nodes_per_mlp_layer[0])\n",
    "        \n",
    "        # hidden layers\n",
    "        self.hidden_layers = nn.ModuleList()   \n",
    "        for k in range(len(nodes_per_mlp_layer) - 1):\n",
    "            self.hidden_layers.append(nn.Linear(nodes_per_mlp_layer[k], nodes_per_mlp_layer[k+1]))\n",
    "\n",
    "        # output layer\n",
    "        self.output_layer = nn.Linear(nodes_per_mlp_layer[k+1],env.action_space.n)\n",
    "        ######## PUT YOUR CODE HERE ########\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Implements the forward pass of the Q Network.\n",
    "        \n",
    "        Args:\n",
    "            x: Input to the Q Network.\n",
    "        \n",
    "        Returns:\n",
    "            Output of the Q Network.\n",
    "        \"\"\"\n",
    "        ######## PUT YOUR CODE HERE ########\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        x = x.to(device)\n",
    "        x = self.input_layer(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "            x = nn.functional.relu(x)\n",
    "        return self.output_layer(x)\n",
    "        ######## PUT YOUR CODE HERE ########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875991cf",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Replay Buffer\n",
    "\n",
    "In addition to the Q Network, our algorithm requires a data structure to store the agent's experiences: Replay Buffer. Let us now define this data structure.\n",
    "\n",
    "Similar to Q Network, many data structure choices exist for the Replay Buffer. We will use a simple buffer to store agent's experiences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2e3926b4",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A buffer to store agent's experiences.\"\"\"\n",
    "    \n",
    "    def __init__(self, env, buffer_size):\n",
    "        \"\"\"Initialize a ring buffer to store agent's experiences.\n",
    "        \n",
    "        Args:\n",
    "            env: An OpenAI Gym environment.\n",
    "            buffer_size: An integer. The total size of the buffer.\n",
    "        \"\"\"\n",
    "        observation_n = env.observation_space.shape[0]\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "        self.observations = np.zeros((self.buffer_size, observation_n), dtype=np.float32)\n",
    "        self.next_observations = np.zeros((self.buffer_size, observation_n), dtype=np.float32)\n",
    "        self.actions = np.zeros((self.buffer_size,), dtype=np.int64)\n",
    "        self.rewards = np.zeros((self.buffer_size,), dtype=np.float32)\n",
    "        self.dones = np.zeros((self.buffer_size,), dtype=np.float32)\n",
    "\n",
    "        ######## PUT YOUR CODE HERE ########\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        ######## PUT YOUR CODE HERE ########\n",
    "    \n",
    "    def add(self, state, action, next_state, reward, done):\n",
    "        \"\"\"Add an experience to the buffer.\n",
    "        \n",
    "        Args:\n",
    "            state: the current environment state\n",
    "            action: the action executed in the state\n",
    "            next_state: the state after executing the action\n",
    "            reward: the reward received after executing the action\n",
    "            done: Boolean denoting whether the task is completed.        \n",
    "        \"\"\"\n",
    "        ######## PUT YOUR CODE HERE ########\n",
    "        self.memory.append((state, action, next_state, reward, done))\n",
    "        ######## PUT YOUR CODE HERE ########\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a mini-batch of experiences from the replay buffer.\n",
    "        \n",
    "        Args:\n",
    "            batch_size: An integer. The size of the mini-batch.\n",
    "        \n",
    "        Returns:\n",
    "            Randomly sampled experiences from the replay buffer.\n",
    "        \"\"\"\n",
    "        indices = np.random.randint(self.buffer_size, size=batch_size)\n",
    "        observations = torch.from_numpy(self.observations[indices])\n",
    "        next_observations = torch.from_numpy(self.next_observations[indices])\n",
    "        actions = torch.from_numpy(self.actions[indices])\n",
    "        rewards = torch.from_numpy(self.rewards[indices])\n",
    "        dones = np.array(self.dones[indices], dtype=np.uint8),    \n",
    "\n",
    "        return observations, actions, next_observations, rewards, dones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f7dd98",
   "metadata": {},
   "source": [
    "### Understanding sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7358809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_n = env.observation_space.shape[0]\n",
    "buffer_size = 200000\n",
    "        \n",
    "observations = np.zeros((buffer_size, observation_n), dtype=np.float32)\n",
    "next_observations = np.zeros((buffer_size, observation_n), dtype=np.float32)\n",
    "actions = np.zeros((buffer_size,), dtype=np.int64)\n",
    "rewards = np.zeros((buffer_size,), dtype=np.float32)\n",
    "dones = np.zeros((buffer_size,), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "76b39e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([], maxlen=200000)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = deque(maxlen=buffer_size)\n",
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f05e5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(self, state, action, next_state, reward, done):\n",
    "    \"\"\"Add an experience to the buffer.\n",
    "    \n",
    "    Args:\n",
    "        state: the current environment state\n",
    "        action: the action executed in the state\n",
    "        next_state: the state after executing the action\n",
    "        reward: the reward received after executing the action\n",
    "        done: Boolean denoting whether the task is completed.        \n",
    "    \"\"\"\n",
    "    ######## PUT YOUR CODE HERE ########\n",
    "    memory.append((state, action, next_state, reward))\n",
    "    ######## PUT YOUR CODE HERE ########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3ddfbee1",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00],\n",
       "       [1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00],\n",
       "       [2.00000e+00, 2.00000e+00, 2.00000e+00, 2.00000e+00, 2.00000e+00,\n",
       "        2.00000e+00],\n",
       "       ...,\n",
       "       [1.99997e+05, 1.99997e+05, 1.99997e+05, 1.99997e+05, 1.99997e+05,\n",
       "        1.99997e+05],\n",
       "       [1.99998e+05, 1.99998e+05, 1.99998e+05, 1.99998e+05, 1.99998e+05,\n",
       "        1.99998e+05],\n",
       "       [1.99999e+05, 1.99999e+05, 1.99999e+05, 1.99999e+05, 1.99999e+05,\n",
       "        1.99999e+05]], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fill observations\n",
    "for i in range(len(observations)):\n",
    "    observations[i]= i\n",
    "\n",
    "observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f8fd9f4a",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  458, 17807, 17239, 16505, 12659, 16448, 10739,  3394,  7987,\n",
       "         425,  1457, 13330,  7371, 10955,  3208, 19876, 13451, 14926,\n",
       "       16889,  9493,  1447,  8972,  6236, 11310,   335,  6645, 18032,\n",
       "        9780,  3607,  1646, 18951,  2202,   372,  4299, 17531,  1570,\n",
       "       13539,  2235, 12847, 18470,  2905,  6155,   186, 10379, 14356,\n",
       "        4303,  3339, 13449, 19208,  7377,  3033,  8573,   439,   125,\n",
       "       13556,  4988, 12040, 18643, 10693,  1858, 15657,  3177,  7999,\n",
       "       19586])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.random.randint(20000, size=64)\n",
    "indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c6386df3",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "observations = torch.from_numpy(observations[indices])\n",
    "test = observations, observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e6682f5e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  458.,   458.,   458.,   458.,   458.,   458.],\n",
       "         [17807., 17807., 17807., 17807., 17807., 17807.],\n",
       "         [17239., 17239., 17239., 17239., 17239., 17239.],\n",
       "         [16505., 16505., 16505., 16505., 16505., 16505.],\n",
       "         [12659., 12659., 12659., 12659., 12659., 12659.],\n",
       "         [16448., 16448., 16448., 16448., 16448., 16448.],\n",
       "         [10739., 10739., 10739., 10739., 10739., 10739.],\n",
       "         [ 3394.,  3394.,  3394.,  3394.,  3394.,  3394.],\n",
       "         [ 7987.,  7987.,  7987.,  7987.,  7987.,  7987.],\n",
       "         [  425.,   425.,   425.,   425.,   425.,   425.],\n",
       "         [ 1457.,  1457.,  1457.,  1457.,  1457.,  1457.],\n",
       "         [13330., 13330., 13330., 13330., 13330., 13330.],\n",
       "         [ 7371.,  7371.,  7371.,  7371.,  7371.,  7371.],\n",
       "         [10955., 10955., 10955., 10955., 10955., 10955.],\n",
       "         [ 3208.,  3208.,  3208.,  3208.,  3208.,  3208.],\n",
       "         [19876., 19876., 19876., 19876., 19876., 19876.],\n",
       "         [13451., 13451., 13451., 13451., 13451., 13451.],\n",
       "         [14926., 14926., 14926., 14926., 14926., 14926.],\n",
       "         [16889., 16889., 16889., 16889., 16889., 16889.],\n",
       "         [ 9493.,  9493.,  9493.,  9493.,  9493.,  9493.],\n",
       "         [ 1447.,  1447.,  1447.,  1447.,  1447.,  1447.],\n",
       "         [ 8972.,  8972.,  8972.,  8972.,  8972.,  8972.],\n",
       "         [ 6236.,  6236.,  6236.,  6236.,  6236.,  6236.],\n",
       "         [11310., 11310., 11310., 11310., 11310., 11310.],\n",
       "         [  335.,   335.,   335.,   335.,   335.,   335.],\n",
       "         [ 6645.,  6645.,  6645.,  6645.,  6645.,  6645.],\n",
       "         [18032., 18032., 18032., 18032., 18032., 18032.],\n",
       "         [ 9780.,  9780.,  9780.,  9780.,  9780.,  9780.],\n",
       "         [ 3607.,  3607.,  3607.,  3607.,  3607.,  3607.],\n",
       "         [ 1646.,  1646.,  1646.,  1646.,  1646.,  1646.],\n",
       "         [18951., 18951., 18951., 18951., 18951., 18951.],\n",
       "         [ 2202.,  2202.,  2202.,  2202.,  2202.,  2202.],\n",
       "         [  372.,   372.,   372.,   372.,   372.,   372.],\n",
       "         [ 4299.,  4299.,  4299.,  4299.,  4299.,  4299.],\n",
       "         [17531., 17531., 17531., 17531., 17531., 17531.],\n",
       "         [ 1570.,  1570.,  1570.,  1570.,  1570.,  1570.],\n",
       "         [13539., 13539., 13539., 13539., 13539., 13539.],\n",
       "         [ 2235.,  2235.,  2235.,  2235.,  2235.,  2235.],\n",
       "         [12847., 12847., 12847., 12847., 12847., 12847.],\n",
       "         [18470., 18470., 18470., 18470., 18470., 18470.],\n",
       "         [ 2905.,  2905.,  2905.,  2905.,  2905.,  2905.],\n",
       "         [ 6155.,  6155.,  6155.,  6155.,  6155.,  6155.],\n",
       "         [  186.,   186.,   186.,   186.,   186.,   186.],\n",
       "         [10379., 10379., 10379., 10379., 10379., 10379.],\n",
       "         [14356., 14356., 14356., 14356., 14356., 14356.],\n",
       "         [ 4303.,  4303.,  4303.,  4303.,  4303.,  4303.],\n",
       "         [ 3339.,  3339.,  3339.,  3339.,  3339.,  3339.],\n",
       "         [13449., 13449., 13449., 13449., 13449., 13449.],\n",
       "         [19208., 19208., 19208., 19208., 19208., 19208.],\n",
       "         [ 7377.,  7377.,  7377.,  7377.,  7377.,  7377.],\n",
       "         [ 3033.,  3033.,  3033.,  3033.,  3033.,  3033.],\n",
       "         [ 8573.,  8573.,  8573.,  8573.,  8573.,  8573.],\n",
       "         [  439.,   439.,   439.,   439.,   439.,   439.],\n",
       "         [  125.,   125.,   125.,   125.,   125.,   125.],\n",
       "         [13556., 13556., 13556., 13556., 13556., 13556.],\n",
       "         [ 4988.,  4988.,  4988.,  4988.,  4988.,  4988.],\n",
       "         [12040., 12040., 12040., 12040., 12040., 12040.],\n",
       "         [18643., 18643., 18643., 18643., 18643., 18643.],\n",
       "         [10693., 10693., 10693., 10693., 10693., 10693.],\n",
       "         [ 1858.,  1858.,  1858.,  1858.,  1858.,  1858.],\n",
       "         [15657., 15657., 15657., 15657., 15657., 15657.],\n",
       "         [ 3177.,  3177.,  3177.,  3177.,  3177.,  3177.],\n",
       "         [ 7999.,  7999.,  7999.,  7999.,  7999.,  7999.],\n",
       "         [19586., 19586., 19586., 19586., 19586., 19586.]]),\n",
       " tensor([[  458.,   458.,   458.,   458.,   458.,   458.],\n",
       "         [17807., 17807., 17807., 17807., 17807., 17807.],\n",
       "         [17239., 17239., 17239., 17239., 17239., 17239.],\n",
       "         [16505., 16505., 16505., 16505., 16505., 16505.],\n",
       "         [12659., 12659., 12659., 12659., 12659., 12659.],\n",
       "         [16448., 16448., 16448., 16448., 16448., 16448.],\n",
       "         [10739., 10739., 10739., 10739., 10739., 10739.],\n",
       "         [ 3394.,  3394.,  3394.,  3394.,  3394.,  3394.],\n",
       "         [ 7987.,  7987.,  7987.,  7987.,  7987.,  7987.],\n",
       "         [  425.,   425.,   425.,   425.,   425.,   425.],\n",
       "         [ 1457.,  1457.,  1457.,  1457.,  1457.,  1457.],\n",
       "         [13330., 13330., 13330., 13330., 13330., 13330.],\n",
       "         [ 7371.,  7371.,  7371.,  7371.,  7371.,  7371.],\n",
       "         [10955., 10955., 10955., 10955., 10955., 10955.],\n",
       "         [ 3208.,  3208.,  3208.,  3208.,  3208.,  3208.],\n",
       "         [19876., 19876., 19876., 19876., 19876., 19876.],\n",
       "         [13451., 13451., 13451., 13451., 13451., 13451.],\n",
       "         [14926., 14926., 14926., 14926., 14926., 14926.],\n",
       "         [16889., 16889., 16889., 16889., 16889., 16889.],\n",
       "         [ 9493.,  9493.,  9493.,  9493.,  9493.,  9493.],\n",
       "         [ 1447.,  1447.,  1447.,  1447.,  1447.,  1447.],\n",
       "         [ 8972.,  8972.,  8972.,  8972.,  8972.,  8972.],\n",
       "         [ 6236.,  6236.,  6236.,  6236.,  6236.,  6236.],\n",
       "         [11310., 11310., 11310., 11310., 11310., 11310.],\n",
       "         [  335.,   335.,   335.,   335.,   335.,   335.],\n",
       "         [ 6645.,  6645.,  6645.,  6645.,  6645.,  6645.],\n",
       "         [18032., 18032., 18032., 18032., 18032., 18032.],\n",
       "         [ 9780.,  9780.,  9780.,  9780.,  9780.,  9780.],\n",
       "         [ 3607.,  3607.,  3607.,  3607.,  3607.,  3607.],\n",
       "         [ 1646.,  1646.,  1646.,  1646.,  1646.,  1646.],\n",
       "         [18951., 18951., 18951., 18951., 18951., 18951.],\n",
       "         [ 2202.,  2202.,  2202.,  2202.,  2202.,  2202.],\n",
       "         [  372.,   372.,   372.,   372.,   372.,   372.],\n",
       "         [ 4299.,  4299.,  4299.,  4299.,  4299.,  4299.],\n",
       "         [17531., 17531., 17531., 17531., 17531., 17531.],\n",
       "         [ 1570.,  1570.,  1570.,  1570.,  1570.,  1570.],\n",
       "         [13539., 13539., 13539., 13539., 13539., 13539.],\n",
       "         [ 2235.,  2235.,  2235.,  2235.,  2235.,  2235.],\n",
       "         [12847., 12847., 12847., 12847., 12847., 12847.],\n",
       "         [18470., 18470., 18470., 18470., 18470., 18470.],\n",
       "         [ 2905.,  2905.,  2905.,  2905.,  2905.,  2905.],\n",
       "         [ 6155.,  6155.,  6155.,  6155.,  6155.,  6155.],\n",
       "         [  186.,   186.,   186.,   186.,   186.,   186.],\n",
       "         [10379., 10379., 10379., 10379., 10379., 10379.],\n",
       "         [14356., 14356., 14356., 14356., 14356., 14356.],\n",
       "         [ 4303.,  4303.,  4303.,  4303.,  4303.,  4303.],\n",
       "         [ 3339.,  3339.,  3339.,  3339.,  3339.,  3339.],\n",
       "         [13449., 13449., 13449., 13449., 13449., 13449.],\n",
       "         [19208., 19208., 19208., 19208., 19208., 19208.],\n",
       "         [ 7377.,  7377.,  7377.,  7377.,  7377.,  7377.],\n",
       "         [ 3033.,  3033.,  3033.,  3033.,  3033.,  3033.],\n",
       "         [ 8573.,  8573.,  8573.,  8573.,  8573.,  8573.],\n",
       "         [  439.,   439.,   439.,   439.,   439.,   439.],\n",
       "         [  125.,   125.,   125.,   125.,   125.,   125.],\n",
       "         [13556., 13556., 13556., 13556., 13556., 13556.],\n",
       "         [ 4988.,  4988.,  4988.,  4988.,  4988.,  4988.],\n",
       "         [12040., 12040., 12040., 12040., 12040., 12040.],\n",
       "         [18643., 18643., 18643., 18643., 18643., 18643.],\n",
       "         [10693., 10693., 10693., 10693., 10693., 10693.],\n",
       "         [ 1858.,  1858.,  1858.,  1858.,  1858.,  1858.],\n",
       "         [15657., 15657., 15657., 15657., 15657., 15657.],\n",
       "         [ 3177.,  3177.,  3177.,  3177.,  3177.,  3177.],\n",
       "         [ 7999.,  7999.,  7999.,  7999.,  7999.,  7999.],\n",
       "         [19586., 19586., 19586., 19586., 19586., 19586.]]))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "fa51e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(batch_size,observations, actions, next_observations,rewards, dones):\n",
    "    \"\"\"Sample a mini-batch of experiences from the replay buffer.\n",
    "    \n",
    "    Args:\n",
    "        batch_size: An integer. The size of the mini-batch.\n",
    "    \n",
    "    Returns:\n",
    "        Randomly sampled experiences from the replay buffer.\n",
    "    \"\"\"\n",
    "    indices = np.random.randint(200000, size=batch_size)\n",
    "    observations = torch.from_numpy(observations[indices])\n",
    "    next_observations = torch.from_numpy(next_observations[indices])\n",
    "    actions = torch.from_numpy(actions[indices])\n",
    "    rewards = torch.from_numpy(rewards[indices])\n",
    "    dones = np.array(dones, dtype=np.uint8)\n",
    "    return observations, actions, next_observations, rewards, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "620aae88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([[0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.uint8))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=sample(64, observations, actions, next_observations,rewards,  dones)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7bc6091b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0f6d18aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ga/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:1970: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  result = asarray(a).shape\n",
      "/home/ga/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.shape(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac60b75f",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Exploration schedule\n",
    "\n",
    "Q Learning typically utilizes epsilon-greedy strategy for exploration. \n",
    "\n",
    "In general, it is useful to explore more initially (when the agent is far from the optimal policy) and less later on in the learning process. To implement this, we can implement a schedule for epsilon.\n",
    "\n",
    "Similar to the Q network and replay buffer architectures, several choices exist for determining the epsilon schedule. We will use a simple linear scheduler to decay epsilon as agent gains more experience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dd03e0fd",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def linear_schedule_for_epsilon(initial_value, final_value, duration, timestep):\n",
    "    \"\"\"Implements a linear scheduler for epsilon.\n",
    "    \n",
    "    Args:\n",
    "        initial_value: (float) Initial value of epsilon.\n",
    "        final_value: (float) Final value of epsilon.\n",
    "        duration: (int) Duration over which to decay epsilon from its initial to final value.\n",
    "        timestep: (int) The current time step.\n",
    "    \n",
    "    Returns:\n",
    "        Value of epsilon at the given timestep.\n",
    "    \"\"\"\n",
    "    slope = (final_value - initial_value) / duration\n",
    "    return max(slope * timestep + initial_value, final_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9d512b",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### General recipe for Q Learning with Function Approximation\n",
    "\n",
    "Now that we have all the building blocks, we will implement the general recipe for Q learning with function approximation. \n",
    "\n",
    "We will use the AgentBase class from Assignment 2 to help us with the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8a1ea849",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AgentBase:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.num_actions = self.env.action_space.n\n",
    "        self.policy = self.make_policy()\n",
    "        self.behavior_policy = self.make_behavior_policy()\n",
    "\n",
    "    def make_policy(self):\n",
    "        \"\"\"\n",
    "        Return a policy function that will be used for evaluation. The policy\n",
    "        takes observation as input and return action\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def make_behavior_policy(self):\n",
    "        \"\"\"\n",
    "        Similar to make_policy, it returns a policy function. But this one used\n",
    "        for interaction with the environment.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def run_episode(self, episode_policy):\n",
    "        \"\"\"\n",
    "        Generate one episode with the given policy\n",
    "        \"\"\"\n",
    "        episode = []\n",
    "        done = False\n",
    "        obs = self.env.reset()\n",
    "        episode_return = 0\n",
    "        while not done:\n",
    "            action = episode_policy(obs)\n",
    "            next_obs, reward, done, _ = self.env.step(action)\n",
    "            episode.append([obs, action, reward, next_obs, done])\n",
    "            obs = next_obs\n",
    "            episode_return += reward\n",
    "\n",
    "        return (episode, episode_return)\n",
    "\n",
    "    def evaluate(self, num_eval_episodes=1000, plot_title=\"Evaluation\"):\n",
    "        \"\"\"Evaluates the agent.\"\"\"\n",
    "        list_returns = []\n",
    "        list_average_returns = []\n",
    "        average_return = 0\n",
    "        for episode_idx in range(num_eval_episodes):\n",
    "            _, episode_return = self.run_episode(self.policy)\n",
    "            average_return += (1. / (episode_idx+1)) * (episode_return - average_return)\n",
    "            list_returns.append(episode_return)\n",
    "            list_average_returns.append(average_return)\n",
    "\n",
    "        print(f\"Average reward {round(average_return, 3)}\")\n",
    "        plt.plot(list_returns,'^',label=\"Return\")\n",
    "        plt.plot(list_average_returns,'r',label=\"Average Return\")\n",
    "        plt.ylabel('Return')\n",
    "        plt.xlabel('Episode#')\n",
    "        plt.title(plot_title)\n",
    "        plt.legend()\n",
    "        plt.ylim(-501, 0.0)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "91f4c3d6",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DeepQLearning(AgentBase):\n",
    "    \"\"\"Implements a Q Learner with function approximation.\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "        env,\n",
    "        buffer_size = 200000,\n",
    "        batch_size = 64,\n",
    "        initial_epsilon = 1.0,\n",
    "        final_epsilon = 0.01,\n",
    "        epsilon_decay_duration = 100000,\n",
    "        learning_rate = 0.001,\n",
    "        num_gradient_updates = 1,\n",
    "        q_network_update_frequency = 1,\n",
    "        target_network_update_frequency = 200,\n",
    "        learning_starts_at_step = 10000):\n",
    "        \"\"\"Initializes the Agent.\n",
    "        \n",
    "        Args:\n",
    "            env: An OpenAI Gym environment.\n",
    "            buffer_size: (integer) Size of the replay buffer.\n",
    "            batch_size: (integer) Size of the mini batch.\n",
    "            initial_epsilon: (float) Initial value of epsilon.\n",
    "            final_epsilon: (float) Final value of epsilon.\n",
    "            epsilon_decay_duration: (integer) Duration over which to decay epsilon.\n",
    "            learning_rate: (float) Learning rate for Q network update.\n",
    "            num_gradient_updates: (integer) Number of stochastic gradient updates with each minibatch.\n",
    "            q_network_update_frequency: (integer) Steps after which to update Q network.\n",
    "            target_network_update_frequency: (integer) Steps after which to update target network.            \n",
    "            learning_starts_at_step: (integer) Step at which to begin learning. Before this, the \n",
    "                agent explores and collects experiences in its replay buffer.\n",
    "        \"\"\"\n",
    "        super().__init__(env=env)\n",
    "        \n",
    "        self.gamma = 0.99 # Assume a discount factor of 0.99\n",
    "        self.current_step = 0\n",
    "        self.learning_starts_at_step = learning_starts_at_step\n",
    "        self.batch_size = batch_size\n",
    "        self.num_gradient_updates = num_gradient_updates\n",
    "        self.q_network_update_frequency = q_network_update_frequency\n",
    "        self.target_network_update_frequency = target_network_update_frequency\n",
    "\n",
    "        # Create exploration scheduler\n",
    "        self.epsilon_scheduler = lambda current_step: linear_schedule_for_epsilon(\n",
    "            initial_epsilon, final_epsilon, epsilon_decay_duration, current_step)      \n",
    "\n",
    "        ######## PUT YOUR CODE HERE ########\n",
    "        self.QNetwork = QNetwork(env)\n",
    "        self.TargetNetwork = QNetwork(env)\n",
    "        self.replay_buffer = ReplayBuffer(env,buffer_size)\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.QNetwork.parameters(), lr=1e-3) # The optimizer will update ONLY the parameters of the policy network\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        ######## PUT YOUR CODE HERE ########\n",
    "\n",
    "        self.state = env.reset()\n",
    "        self.list_returns = []\n",
    "        self.list_average_returns = []\n",
    "        self.average_return = 0.\n",
    "        self.list_moving_average_returns = []\n",
    "        self.moving_average_returns_by_step = np.empty([200000])\n",
    "    \n",
    "    @property\n",
    "    def epsilon(self):\n",
    "        return self.epsilon_scheduler(self.current_step)\n",
    "\n",
    "\n",
    "    def make_policy(self):\n",
    "        def policy_func(observation):\n",
    "            ######## PUT YOUR CODE HERE ########\n",
    "            with torch.no_grad():\n",
    "              observation = torch.FloatTensor(observation).cpu().unsqueeze(0)\n",
    "            out = self.QNetwork.forward(observation).cpu()\n",
    "\n",
    "            return torch.argmax(out).item()\n",
    "            \"\"\"\n",
    "            return torch.argmax(out).item()\n",
    "            obs_t = torch.as_tensor (observation, dtype= torch.float32)\n",
    "            q_values = QNetwork.forward(QNetwork(nn.Module),obs_t)\n",
    "            max_q_index = torch.argmax(q_values, dim = 1)\n",
    "            action = max_q_index.detach().item()\n",
    "            return action\n",
    "\n",
    "            temp = self.Q[observation]\n",
    "            best_action = np.argmax(temp)\n",
    "            return best_action  \n",
    "            \"\"\"\n",
    "            ######## PUT YOUR CODE HERE ########\n",
    "\n",
    "        return policy_func\n",
    "\n",
    "    def make_behavior_policy(self):\n",
    "        def policy_func(observation):\n",
    "            ######## PUT YOUR CODE HERE ########\n",
    "            if random.random() < self.epsilon:\n",
    "            # Random action\n",
    "                return self.env.action_space.sample()\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    observation = torch.FloatTensor(observation).cpu().unsqueeze(0)\n",
    "                    out = self.QNetwork.forward(observation).cpu()\n",
    "\n",
    "            return torch.argmax(out).item()\n",
    "            \"\"\" \n",
    "            prob = np.ones(env.action_space.n, dtype = float) * self.epsilon / env.action_space.n\n",
    "            best_action = np.argmax(self.Q[observation])\n",
    "            prob[best_action] += 1. - self.epsilon\n",
    "            A= np.random.choice((0,1), p= list(prob))\n",
    "            return A \n",
    "            \"\"\"  \n",
    "            ######## PUT YOUR CODE HERE ########\n",
    "\n",
    "        return policy_func\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"Update the agent.\"\"\"                      \n",
    "        ######## PUT YOUR CODE HERE ########\n",
    "        batch = self.replay_buffer.sample(self.batch_size)\n",
    "        states, actions, rewards, dones, next_states = batch\n",
    "        done_mask = torch.ByteTensor(dones)\n",
    "\n",
    "        \"\"\"  \n",
    "       next_observations,\n",
    "        states      = batch[0]\n",
    "        actions     = batch[1]\n",
    "        rewards     = batch[3]\n",
    "        # Compute a mask of non-final states (all the elements where the next state is not None)\n",
    "        non_final_next_states = [s[2] for s in batch if s[2] is not None] # the next state can be None if the game has ended\n",
    "        non_final_mask = [s[2] is not None for s in batch] \"\"\"\n",
    "\n",
    "        # Compute Q values \n",
    "        self.QNetwork.train()\n",
    "        q_values = self.QNetwork(states)\n",
    "        # Select the proper Q value for the corresponding action taken Q(s_t, a)\n",
    "        state_action_values = q_values.gather(1, actions.unsqueeze(1).cpu())\n",
    "\n",
    "\n",
    "        # Compute the value function of the next states using the target network V(s_{t+1}) = max_a( Q_target(s_{t+1}, a)) )\n",
    "        with torch.no_grad():\n",
    "            self.TargetNetwork.eval()\n",
    "            next_state_max_q_values = self.TargetNetwork(states).max(1)[0]\n",
    "            next_state_max_q_values[done_mask] = 0.0\n",
    "            next_state_max_q_values = next_state_max_q_values.detach()\n",
    "\n",
    "\n",
    "        # Compute the expected Q values\n",
    "        expected_state_action_values = rewards + (next_state_max_q_values * self.gamma)\n",
    "        expected_state_action_values = expected_state_action_values.unsqueeze(1)# Set the required tensor shape\n",
    "\n",
    "        # Compute the Huber loss\n",
    "        loss = self.loss_fn(state_action_values, expected_state_action_values)\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "    # Apply gradient clipping \n",
    "        nn.utils.clip_grad_norm_(self.QNetwork.parameters(), 2)\n",
    "        self.optimizer.step()\n",
    "        ######## PUT YOUR CODE HERE ########\n",
    "        \n",
    "    \n",
    "    def train(self, num_train_episodes, make_plot=False):\n",
    "        \n",
    "        for episode_idx in range(num_train_episodes):\n",
    "            # Reset environment before beginning the episode\n",
    "            done = False\n",
    "            self.state = self.env.reset()\n",
    "            episode_return = 0\n",
    "            \n",
    "            # Run the episode and update the policy \n",
    "            while not done:\n",
    "                # First, generate a step with behavior policy\n",
    "                action = self.behavior_policy(self.state)\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                \n",
    "                # Update the replay buffer\n",
    "                self.replay_buffer.add(self.state, action, next_state, reward, done)\n",
    "            \n",
    "                # Second, update the agent\n",
    "                self.update()\n",
    "                \n",
    "                # Prepare for next step\n",
    "                self.state = next_state\n",
    "                self.current_step += 1\n",
    "                episode_return += reward\n",
    "                if self.current_step < 200000:\n",
    "                    if len(self.list_moving_average_returns) > 0:\n",
    "                      self.moving_average_returns_by_step[self.current_step] = self.list_moving_average_returns[-1]\n",
    "                    else:\n",
    "                      self.moving_average_returns_by_step[self.current_step] = -500.\n",
    "\n",
    "                if self.current_step % 10000 == 0:\n",
    "                    print(f\"Timestep: {self.current_step}, episode reward (moving average, 20 episodes): {round(self.list_moving_average_returns[-1],2)}\")\n",
    "            \n",
    "            # Store the return for evaluation\n",
    "            self.list_returns.append(episode_return)\n",
    "            self.average_return = np.mean(np.asarray(self.list_returns))\n",
    "            self.list_average_returns.append(self.average_return)\n",
    "\n",
    "            if len(self.list_returns) > 20:\n",
    "                self.list_moving_average_returns.append(\n",
    "                  np.mean(np.asarray(self.list_returns[-20:])))\n",
    "            else:\n",
    "                self.list_moving_average_returns.append(self.average_return)\n",
    "\n",
    "        if make_plot:\n",
    "            plt.plot(self.list_returns,'^',label=\"Return\")\n",
    "            plt.plot(self.list_average_returns,'r',label=\"Average Return (all episodes)\")\n",
    "            plt.plot(self.list_moving_average_returns,'b',label=\"Average Return (last 20 episodes)\")\n",
    "            plt.ylabel('Return')\n",
    "            plt.xlabel('Episode#')\n",
    "            plt.title('Performance during training')\n",
    "            plt.ylim(-501, 0.0)\n",
    "            plt.legend()        \n",
    "            plt.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29295e2",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Training the Agent\n",
    "\n",
    "Having implemented the agent, now we will train it using the default hyperparameters provided in the class definition and observe its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d7b430",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ReplayBuffer.sample(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "724e8bb4",
   "metadata": {
    "id": "724e8bb4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"Acrobot-v1\")\n",
    "agent_001 = DeepQLearning(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "3c2cb127",
   "metadata": {
    "id": "3c2cb127",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward -182.49\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent_001.evaluate(plot_title=\"Performance before training\", num_eval_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "06932c10",
   "metadata": {
    "id": "06932c10",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected TensorOptions(dtype=unsigned char, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)) (got TensorOptions(dtype=float, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [243], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m agent_001\u001b[39m.\u001b[39mtrain(\u001b[39m1000\u001b[39m, make_plot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn [237], line 181\u001b[0m, in \u001b[0;36mDeepQLearning.train\u001b[0;34m(self, num_train_episodes, make_plot)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplay_buffer\u001b[39m.\u001b[39madd(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, action, next_state, reward, done)\n\u001b[1;32m    180\u001b[0m \u001b[39m# Second, update the agent\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate()\n\u001b[1;32m    183\u001b[0m \u001b[39m# Prepare for next step\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m next_state\n",
      "Cell \u001b[0;32mIn [237], line 121\u001b[0m, in \u001b[0;36mDeepQLearning.update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m  batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplay_buffer\u001b[39m.\u001b[39msample(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size)\n\u001b[1;32m    120\u001b[0m  states, actions, rewards, dones, next_states \u001b[39m=\u001b[39m batch\n\u001b[0;32m--> 121\u001b[0m  done_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mByteTensor(dones)\n\u001b[1;32m    123\u001b[0m  \u001b[39m\"\"\"  \u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mnext_observations,\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39m states      = batch[0]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m non_final_next_states = [s[2] for s in batch if s[2] is not None] # the next state can be None if the game has ended\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m non_final_mask = [s[2] is not None for s in batch] \"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m  \u001b[39m# Compute Q values \u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected TensorOptions(dtype=unsigned char, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)) (got TensorOptions(dtype=float, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)))"
     ]
    }
   ],
   "source": [
    "agent_001.train(1000, make_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "JcvssSrlJylN",
   "metadata": {
    "id": "JcvssSrlJylN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward -500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent_001.evaluate(plot_title=\"Performance after training\", num_eval_episodes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xRvLQpb6XKOJ",
   "metadata": {
    "id": "xRvLQpb6XKOJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Problem 1.2\n",
    "\n",
    "Now that we have implemented the general recipe, let us run ablation studies to assess importance of different components of the Deep Q Learning algorithm.\n",
    "\n",
    "First, we will implement and assess the performance of the original Q Learning with naive function approximation, i.e., without the use of replay buffer and target networks. Note that this is a special case of our general recipe and, in general, we do not expect to work in practice. Let us see if it works for the Acrobot environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_V4_ZE-4fRv4",
   "metadata": {
    "id": "_V4_ZE-4fRv4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class OnlineDeepQLearning(DeepQLearning):\n",
    "    \"\"\"Implements Online Q Learner with function approximation.\"\"\"\n",
    "    \n",
    "    ######## PUT YOUR CODE HERE ########\n",
    "\n",
    "    ######## PUT YOUR CODE HERE ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xPWojLBQbmwG",
   "metadata": {
    "id": "xPWojLBQbmwG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"Acrobot-v1\")\n",
    "agent_002 = OnlineDeepQLearning(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fLIV58UtcAC2",
   "metadata": {
    "id": "fLIV58UtcAC2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agent_002.train(500, make_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q_JhG9ZUds3O",
   "metadata": {
    "id": "q_JhG9ZUds3O",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let us bring back one of the components at a time that made the algorithm successful in Problem 1. First, we will bring back only the replay buffer (and not the target network) and observe its effect on the agent's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaEKoe6hkBv",
   "metadata": {
    "id": "cfaEKoe6hkBv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DeepQLearningWithoutTargetNetwork(DeepQLearning):\n",
    "    \"\"\"Implements a Deep Q Learner without target network.\"\"\"\n",
    "    \n",
    "    ######## PUT YOUR CODE HERE ########\n",
    "\n",
    "    ######## PUT YOUR CODE HERE ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fkmpYdDTd-WL",
   "metadata": {
    "id": "fkmpYdDTd-WL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"Acrobot-v1\")\n",
    "agent_003 = DeepQLearningWithoutTargetNetwork(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_kc9HBMGeaHK",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_kc9HBMGeaHK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agent_003.train(1000, make_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f-kt9K_e-vU",
   "metadata": {
    "id": "6f-kt9K_e-vU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we will bring back only the target network (and not the replay buffer) and observe its effect on the agent's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oCKmIA-fh_6N",
   "metadata": {
    "id": "oCKmIA-fh_6N",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DeepQLearningWithoutReplayBuffer(DeepQLearning):\n",
    "    \"\"\"Implements a Deep Q Learner without replay buffer.\"\"\"\n",
    "    ######## PUT YOUR CODE HERE ########\n",
    "\n",
    "    ######## PUT YOUR CODE HERE ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QD788cSIieA6",
   "metadata": {
    "id": "QD788cSIieA6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"Acrobot-v1\")\n",
    "agent_004 = DeepQLearningWithoutReplayBuffer(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4CNVjTdPid2G",
   "metadata": {
    "id": "4CNVjTdPid2G",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agent_004.train(1000, make_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mXK_YMAYi8sx",
   "metadata": {
    "id": "mXK_YMAYi8sx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In a single plot, show the performance of the four variants that you have implemented above. Specifications of the plot\n",
    "- X axis: Number of Timesteps (0 to 100000)\n",
    "- Y axis: 20-episode simple moving average of episodic rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FQyBCL7HjIs_",
   "metadata": {
    "id": "FQyBCL7HjIs_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "######## PUT YOUR CODE HERE ########\n",
    "\n",
    "######## PUT YOUR CODE HERE ########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qbs90XholVCz",
   "metadata": {
    "id": "qbs90XholVCz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Problem 1.3\n",
    "\n",
    "Select any one hyperparameter of the DeepQLearning agent and study its effect on the agent's performance. You should try at least five different values of this hyperparameter. In a single plot, show the performance of the agent for different values of hyperparameter.  Specifications of the plot\n",
    "- X axis: Number of Timesteps (0 to 100000)\n",
    "- Y axis: 20-episode simple moving average of episodic rewards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j9JlG7oqwEha",
   "metadata": {
    "id": "j9JlG7oqwEha",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "######## PUT YOUR CODE HERE ########\n",
    "\n",
    "######## PUT YOUR CODE HERE ########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tffNcpDjveBG",
   "metadata": {
    "id": "tffNcpDjveBG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Problem 1.4\n",
    "\n",
    "While applying RL in real world, you may consider the use of off-the-shelf implementation of RL algorithms. The package [Stable Baselines 3](stable-baselines3.readthedocs.io/) aims to provide a set of reliable implementations of RL algorithms in PyTorch. \n",
    "\n",
    "Familiarize yourself with this package and use its implementation of Deep Q Network to learn the optimal policy for the Acrobot environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OLCEfJRQqhjx",
   "metadata": {
    "id": "OLCEfJRQqhjx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "######## PUT YOUR CODE HERE ########\n",
    "\n",
    "######## PUT YOUR CODE HERE ########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oJ8_eWPewRtB",
   "metadata": {
    "id": "oJ8_eWPewRtB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In a single plot, compare the performance of your implementation of the algorithm in Problem 1.1. with the one that you implemented above (Problem 1.4). Specifications of the plot\n",
    "- X axis: Number of Timesteps (0 to 100000)\n",
    "- Y axis: 20-episode simple moving average of episodic rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vFZP_dinqo4M",
   "metadata": {
    "id": "vFZP_dinqo4M",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "######## PUT YOUR CODE HERE ########\n",
    "\n",
    "######## PUT YOUR CODE HERE ########"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5542afc9645e829686dd49431b87fb87d8247b98aee894d9a9effffe0045c8ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
